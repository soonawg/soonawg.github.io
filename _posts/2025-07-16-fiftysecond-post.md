---
title: "YOLO: vision"
layout: post
date: 2025-07-16 12:42:00 +0900
categories: study
---

HW 플랫폼, 임베디드, 통신과 네트웤, 제어/설계에 대해 공부했지만 너무 내용이 길어질 것 같아 해당 내용들은 블로그에 정리하지 않겠다.

이번 블로그 글은 위 내용들의 공부를 마치고 시작한 공부인 비전에 대해서 정리해보고자 한다.


# YOLO
YOLO란, 이미지를 한 번에 전체적으로 분석해 "무엇이 어디에 있는지"를 빠르게 탐지하는 실시간 객체 탐지 모델이다.

## YOLO의 핵심 아이디어 정리
- 이미지를 grid로 나눈 후,
- 각 grid 셀에서 객체가 있을 확률, 클래스, Bounding Box 좌표를 예측한다.
- 모든 처리를 한번에(End-to-End) 수행하여 빠르고 효율적이다.

## YOLO 아키텍처 요약
YOLO는 크게 3단계 구조로 이루어져 있다:
### 1. Backbone (특징 추출기)
입력 이미지를 받아서 특징을 추출하는 CNN 네트워크
- 고전적인 CNN과 유사하게 여러 층의 Conv + BN + ReLU 구조로 구성됨
- YOLOv5 ~ v8에서는 CSP 구조를 사용해서 속도와 정확도 모두 향상됨

### 2. Neck (피처 통합기)
여러 스케일의 특징을 결합해 객체를 더 잘 인식하도록 도와주는 중간 계층

**왜 필요한가?**
- 작은 물체는 shallow feature (초기 레이어)
- 큰 물체는 deep feature (후반 레이어)에서 잘 보이기 때문

**주요 구성**
- FPN (Feature Pyramid Network): 위에서 아래로 피처 업샘플링
- PANet: 아래에서 위로 피처 재전달 -> 양방향 연결


### 3. Head (탐지기)
위치, 클래스, 신뢰도를 예측하는 마지막 레이어

**출력값 구조**
각 예측 박스는 보통 다음을 포함한다:
- x, y
    - 중심 좌표
- w, h
    - 박스 너비/높이
- obj conf
    - 객체가 있을 확률
- class conf
    - 클래스 별 확률

